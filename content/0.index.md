---
title: Home
navigation: false
layout: page
main:
  fluid: false
---

:ellipsis{right=0px width=75% blur=150px}

::block-hero
---
cta:
  - Get started
  - /introduction/getting-started
secondary:
  - Open on GitHub â†’
  - https://github.com/seonglae/llama2gptq
---

#title
LLaMa2 GPTQ

#description
Question Answering AI who can provide answers with source documents based on [Texonom](https://texonom.com).

#extra
  ::list
  - Made with [Langchain](https://github.com/hwchase17/langchain)
  - Chat UI support made by Streamlit Web Component
  - Rye based python package management
  ::

#support
  ::terminal
  ---
  content:
  - git clone https://github.com/seonglae/llama2gptq
  - cd llama2gptq
  - git clone https://huggingface.co/datasets/texonom/llama2gptq db
  - rye sync
  - streamlit run chat.py
  ---
  ::
  <p align="center">
  <img src="https://github.com/seonglae/llama2gptq/raw/main/img/chat.png" style="max-width: 40em; width: 100%">
  </p>
::

::card-grid
#title
What's included

#root
:ellipsis{left=0px width=40rem top=10rem blur=140px}

#default
  ::card{icon=logos:python}
  #title
  Langchain
  #description
  [Langchain](https://github.com/hwchase17/langchain) made it easy to Prompt engineering of referencing source documents.
  ::

  ::card{icon=cib:nvidia}
  #title
  GPTQ
  #description
  CUDA based int4 Model quantization make model available to run in local environment.
  ::

  ::card{icon=logos:chroma}
  #title
  ChromaDB
  #description
  Vector database make LLaMa2 GPTQ provide responses with reference documents
  ::

  ::card{icon=logos:streamlit}
  #title
  Web UI
  #description
  Chat UI provided for conversation with private AI without any external API
  ::
::
