[{"data":1,"prerenderedAt":21},["Reactive",2],{"search-api":3},[4,11],{"id":5,"path":6,"dir":7,"title":8,"description":7,"keywords":9,"body":10},"content:0.index.md","/","","Home",[],"     LLaMa2 GPTQ   Question Answering AI who can provide answers with source documents based on   Texonom .     Made with   Langchain  Chat UI support made by Streamlit Web Component  Rye based python package management         \n    \n    \n   \n      What's included      Langchain    Langchain  made it easy to Prompt engineering of referencing source documents.    GPTQ   CUDA based int4 Model quantization make model available to run in local environment.    ChromaDB   Vector database make LLaMa2 GPTQ provide responses with reference documents    Web UI   Chat UI provided for conversation with private AI without any external API",{"id":12,"path":13,"dir":14,"title":15,"description":16,"keywords":17,"body":20},"content:1.introduction:1.getting-started.md","/introduction/getting-started","introduction","Getting Started","From your Markdown files to a deployed website in few minutes.",[18,19],"Install","Boom!","  Getting Started  From your Markdown files to a deployed website in few minutes.  Install   If you don't have rye python package manager, install in   here  Clone repository and install dependencies     git   clone   https://github.com/seonglae/llama2gptq\n   cd   llama2gptq\n   git   clone   https://huggingface.co/datasets/texonom/llama2gptq   db\n   rye   sync\n   Run web UI\nActiavet rye venv environment and run Web UI      source   .venv/Scripts/activate\n   streamlit   run   chat.py\n     source   .venv/bin/activate\n   streamlit   run   chat.py\n     source   .venv/bin/activate\n   streamlit   run   chat.py\n \n     Boom!  Chat supported with related documents \n    \n    CLI streaming demo \n    \n   \n     âœ¨ Well done! A browser window should automatically open for   http://localhost:8501  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",1700622308285]